{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import torch\n",
    "from utils.general import (check_file, check_img_size, cv2, non_max_suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/theo/Desktop/flasktuto/AppBrandSeeker/video/Faire GLISSER un BUS  Ã‡A FAIT QUOI .mp4'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = YouTube('https://www.youtube.com/watch?v=WfuE61ZkuRo')\n",
    "video = yt.streams.filter(file_extension='mp4').first()\n",
    "video.download('video/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "def pytube_dl(url):\n",
    "    yt = YouTube(str(url))\n",
    "    video = yt.streams.filter(file_extension='mp4').first()\n",
    "    video.download('video/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/theo/.var/app/com.visualstudio.code/cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-7-4 Python-3.10.4 torch-1.12.0+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7112611 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt')\n",
    "\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size((640, 640), s=stride)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadImages(\"video/\", img_size=imgsz, stride=stride, auto=pt, only_vids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, im, im0s, vid_cap, s, frame = dataset.__iter__().__next__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_framerate = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "real_framerate = initial_framerate / round(initial_framerate / 15)\n",
    "total_frames = dataset.frames\n",
    "dataset.frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = dataset.frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for path, im, im0s, vid_cap, s, frame in tqdm(dataset, total=total_frames):\n",
    "    i+=1\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-7-4 Python-3.10.4 torch-1.12.0+cu102 CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = select_device('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, seen = [0.0, 0.0, 0.0], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.filtering import filter_output\n",
    "from utils.pdf_generator import pdf_generator, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saving_predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_unprocessed_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_timing_start = time_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb#ch0000012?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m brand_count:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb#ch0000012?line=39'>40</a>\u001b[0m     filtered_output \u001b[39m=\u001b[39m filter_output(brand_count, framerate)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb#ch0000012?line=40'>41</a>\u001b[0m     pdf_generator(path, filtered_output, save_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb#ch0000012?line=41'>42</a>\u001b[0m     \u001b[39m# cv2.imshow(im, framerate)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theo/Desktop/flasktuto/AppBrandSeeker/test.ipynb#ch0000012?line=43'>44</a>\u001b[0m     \u001b[39mif\u001b[39;00m save_unprocessed_output:\n",
      "File \u001b[0;32m~/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py:198\u001b[0m, in \u001b[0;36mpdf_generator\u001b[0;34m(video_path, output_dict, save_dir)\u001b[0m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=188'>189</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=189'>190</a>\u001b[0m \u001b[39m    _summary_: This function render the pdf \u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=190'>191</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=194'>195</a>\u001b[0m \u001b[39m    return: video_name.pdf\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=195'>196</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=196'>197</a>\u001b[0m \u001b[39m# Write frames and return a path list\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=197'>198</a>\u001b[0m video_name, length, confidence_list, brand_list, path_list, path_cropped_list, frame_seq_list \u001b[39m=\u001b[39m load_frames(video_path, output_dict)\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=199'>200</a>\u001b[0m \u001b[39m# Video length in m, s\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=200'>201</a>\u001b[0m minutes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(length\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py:139\u001b[0m, in \u001b[0;36mload_frames\u001b[0;34m(video_path, output_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=136'>137</a>\u001b[0m fps \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mget(cv2\u001b[39m.\u001b[39mCAP_PROP_FPS)\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=137'>138</a>\u001b[0m frame_count \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cap\u001b[39m.\u001b[39mget(cv2\u001b[39m.\u001b[39mCAP_PROP_FRAME_COUNT)) \n\u001b[0;32m--> <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=138'>139</a>\u001b[0m length \u001b[39m=\u001b[39m frame_count\u001b[39m/\u001b[39;49mfps\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=140'>141</a>\u001b[0m \u001b[39m# create all list needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/theo/Desktop/flasktuto/AppBrandSeeker/utils/pdf_generator.py?line=141'>142</a>\u001b[0m frame_seq_list \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "for path, im, im0s, vid_cap, s, frame in tqdm(dataset, total=total_frames):\n",
    "\n",
    "        # skip the frame if it isn't in the specified framerate\n",
    "        if frame % round(initial_framerate / framerate) != 0:\n",
    "            continue\n",
    "\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.float()\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        pred = model(im)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres=0.35, max_det=5)\n",
    "        pred = pred[0].tolist()\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        has_prediction = len(pred)\n",
    "        if has_prediction:\n",
    "            for brand in pred:\n",
    "                label = names[int(brand[5])]\n",
    "\n",
    "                # Retrieve or create a dictionnary key for the label and add the bbox, confidence and frame of the prediction\n",
    "                brand_count[label] = brand_count.get(label, {\"bbox\": [], \"confidence\": [], \"frame\": []})\n",
    "                brand_count[label][\"bbox\"].append(brand[0:4])\n",
    "                brand_count[label][\"confidence\"].append(brand[4])\n",
    "                brand_count[label][\"frame\"].append(frame)\n",
    "    \n",
    "    # Generate an output if a prediction has been made\n",
    "if brand_count:\n",
    "    filtered_output = filter_output(brand_count, framerate)\n",
    "    pdf_generator(path, filtered_output, save_dir)\n",
    "    # cv2.imshow(im, framerate)\n",
    "\n",
    "    if save_unprocessed_output:\n",
    "        with open(f\"{save_dir}/{normalize(path)}.txt\", \"w\") as f:\n",
    "            f.write(str(brand_count))\n",
    "else:\n",
    "    print(\"No prediction has been made\")\n",
    "\n",
    "\n",
    "pred_timing_stop = time_sync()\n",
    "pred_timing = pred_timing_stop - pred_timing_start\n",
    "print(\"Pred took %.2fs (%.2ffps)\" % (pred_timing, ((total_frames / initial_framerate) * real_framerate) / pred_timing))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67aaf1d5ed21201ba7a8b0f60d8490dc144250f7c4f404e185860014192452eb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('flaskenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
